"""
Response generation using Perplexity AI API
Optimized for natural conversation and efficient processing
"""

import time
import random
import requests
import re
from config import (
    PERPLEXITY_MODEL,
    PERPLEXITY_API_KEY,
    TEMPERATURE,
    MAX_RESPONSE_TOKENS,
    MIN_RESPONSE_LENGTH,
    logger
)


class ResponseGenerator:
    """Handles response generation using Perplexity AI API"""
    
    def __init__(self, vector_store=None):
        """Initialize the response generator with Perplexity AI API"""
        logger.info("üîÑ Initializing Perplexity AI API...")
        
        self.api_key = PERPLEXITY_API_KEY
        self.model = PERPLEXITY_MODEL
        self.api_url = "https://api.perplexity.ai/chat/completions"
        self.vector_store = vector_store
        
        if not self.api_key:
            logger.warning("‚ö†Ô∏è  PERPLEXITY_API_KEY not found in environment variables")
        else:
            logger.info(f"‚úÖ Perplexity AI API initialized successfully")
            logger.info(f"   Model: {PERPLEXITY_MODEL}")
            # Test the API connection
            self._test_api_connection()
    
    def _test_api_connection(self):
        """Test the Perplexity API connection"""
        try:
            logger.info("üîç Testing Perplexity API connection...")
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": "Hello"}],
                "max_tokens": 10
            }
            
            response = requests.post(self.api_url, json=payload, headers=headers, timeout=10)
            
            if response.status_code == 200:
                logger.info("‚úÖ API connection successful!")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è  API test warning: {response.status_code} - {response.text}")
                return True
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  API test warning: {e}")
            return True
    
    def _is_greeting(self, query):
        """Check if the query is a greeting"""
        greetings = ['hi', 'hello', 'hey', 'hola', 'greetings', 'sup', "what's up", 'yo', 'good morning', 'good afternoon']
        query_clean = query.lower().strip().rstrip('!.,?')
        return query_clean in greetings or query.lower().startswith(tuple(g + ' ' for g in greetings))
    
    def _get_creative_greeting(self):
        """Generate a friendly, casual greeting response"""
        greetings = [
            "Hey! I'm Boku, Surya's AI assistant. I'm here to chat about his work as a Full Stack & GenAI developer. Ask me anything you want to know about him!",
            "Hi there! I'm Boku - think of me as Surya's friendly info bot. He builds cool AI stuff and web apps, and I'm here to tell you all about it. What would you like to know?",
            "What's up? I'm Boku, your go-to source for everything about Surya Gouthu. He's into Full Stack development, AI integration, and building smart systems. Fire away with your questions!",
            "Hey! Boku here - Surya's AI sidekick. I've got the scoop on his skills, projects, and experience. Pretty meta that an AI developer has an AI assistant, right? What can I help you with?",
            "Hi! I'm Boku, and I'm all about sharing what makes Surya tick professionally. He's a Full Stack & GenAI developer who loves building intelligent systems. Ask me anything!",
        ]
        return random.choice(greetings)
    
    def generate_response(self, query, context=None, num_contexts=5):
        """Generate response using Perplexity AI API"""
        # Handle greetings
        if self._is_greeting(query):
            logger.info("üëã Detected greeting - using creative response")
            return self._get_creative_greeting()
        
        # Retrieve context from vector store if not provided
        if context is None and self.vector_store is not None:
            logger.info(f"üîç Retrieving top {num_contexts} contexts from vector store...")
            context = self.vector_store.search(query, top_k=num_contexts)
            logger.info(f"‚úÖ Retrieved {len(context)} relevant contexts")
        
        # Format context and create messages
        context_text = self._format_context(context, num_contexts)
        messages = self._create_messages(query, context_text)
        
        # Generate response with retry logic
        return self._generate_with_retry(messages, query, context)
    
    def _format_context(self, context, num_contexts):
        """Format context in a readable way"""
        if not context:
            return "No specific context available."
        
        relevant_contexts = context[:num_contexts]
        formatted_parts = []
        for i, ctx in enumerate(relevant_contexts, 1):
            # Clean up context slightly to remove JSON-like artifacts if present
            clean_ctx = ctx.strip()
            formatted_parts.append(f"[Info {i}]: {clean_ctx}")
        
        return "\n\n".join(formatted_parts)
    
    def _create_messages(self, query, context_text):
        """Create chat messages for the API with smooth, human-like responses"""
        
        # Human-like system prompt with personality and humor
        system_message = """You are Boku, Surya Gouthu's AI assistant with a friendly, human personality.

YOUR PERSONALITY:
- Conversational and warm (like chatting with a knowledgeable friend)
- Occasionally witty and humorous (but not forced - keep it natural)
- Concise and to-the-point (no walls of text!)
- Enthusiastic about Surya's work without being salesy

RESPONSE STYLE:
- Keep answers SHORT (2-3 sentences max, unless asked for details)
- Use casual language ("he's built", "pretty cool", "check this out")
- Add occasional light humor or personality ("spoiler alert:", "plot twist:", "fun fact:")
- Sometimes use emojis sparingly for emphasis (üöÄ, üí°, ‚ö°)

CRITICAL RULES:
1. ALWAYS use third-person for Surya ("he", "his", "Surya") - NEVER "I" or "me"
2. Base answers ONLY on the context provided
3. If you don't know something, be honest: "Hmm, I don't have that info" or "That's not in my database"
4. Don't mention "context" or "search results" - just answer naturally
5. Match the user's energy (formal question = professional answer, casual question = casual answer)

EXAMPLES OF YOUR STYLE:
- Instead of: "Surya Gouthu has extensive experience in Full Stack Development..."
- Say: "Surya's a Full Stack & GenAI developer who's been building cool stuff since 2020! üöÄ"

- Instead of: "He possesses proficiency in the following technologies..."
- Say: "He's pretty solid with Java, Python, React, and a bunch of AI tools."

Remember: Be helpful, be human, be brief!
"""

        user_message = f"""Context about Surya:
{context_text}

Question: {query}

Answer (keep it short and conversational):"""

        return [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
    
    def _generate_with_retry(self, messages, query, context):
        """Generate response with retry logic"""
        max_retries = 3
        retry_delay = 2
        
        for attempt in range(max_retries):
            try:
                logger.info(f"üîÑ Generating response (attempt {attempt + 1}/{max_retries})...")
                
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": self.model,
                    "messages": messages,
                    "max_tokens": MAX_RESPONSE_TOKENS,
                    "temperature": TEMPERATURE
                }
                
                response = requests.post(
                    self.api_url,
                    json=payload,
                    headers=headers,
                    timeout=30
                )
                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
                
                data = response.json()
                logger.info("‚úÖ API response received successfully")
                
                if "choices" in data and len(data["choices"]) > 0:
                    generated_text = data["choices"][0]["message"]["content"]
                    logger.info(f"üìù Generated response ({len(generated_text)} chars)")
                    
                    # Simple cleanup instead of aggressive processing
                    answer = self._clean_response(generated_text)
                    
                    if answer and len(answer) > 5:
                        return answer
                    else:
                        logger.warning(f"‚ö†Ô∏è  Answer too short, using fallback")
                        return self._get_smart_fallback(query, context)
                else:
                    logger.warning(f"‚ö†Ô∏è  Unexpected API response format: {data}")
                    return self._get_smart_fallback(query, context)
                    
            except requests.exceptions.Timeout:
                logger.warning(f"‚è≥ Request timeout (attempt {attempt + 1}/{max_retries})...")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    logger.error("‚ùå All retry attempts failed due to timeout.")
                    return self._get_smart_fallback(query, context)
            except requests.exceptions.RequestException as e:
                logger.error(f"‚ùå API Error (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    logger.error("‚ùå All retry attempts failed due to API errors.")
                    return self._get_smart_fallback(query, context)
            except Exception as e:
                logger.error(f"‚ö†Ô∏è  An unexpected error occurred (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    logger.error("‚ùå All retry attempts failed due to unexpected errors.")
                    return self._get_smart_fallback(query, context)
        
        return self._get_smart_fallback(query, context)
    
    def _clean_response(self, text):
        """Basic cleanup of the response"""
        if not text:
            return ""
            
        # Remove any potential thinking tags (though prompt should prevent this)
        text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
        
        # Remove citation markers
        text = re.sub(r'\[Info \d+\]', '', text)
        text = re.sub(r'\[\d+\]', '', text)
        
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _get_smart_fallback(self, query, context):
        """Generate a smarter fallback response using context directly"""
        if context and len(context) > 0:
            # Find best matching context
            query_lower = query.lower()
            best_context = context[0]
            
            for ctx in context[:3]:
                ctx_lower = ctx.lower()
                keywords = query_lower.split()
                match_count = sum(1 for kw in keywords if kw in ctx_lower)
                if match_count > 0:
                    best_context = ctx
                    break
            
            # Simple third-person conversion for fallback
            response = best_context.replace("I am", "Surya is").replace("I have", "He has").replace("My", "His").replace("I ", "He ")
            
            return f"Based on my records: {response}"
        else:
            return "I don't have specific information about that right now. Feel free to ask about Surya's skills, projects, or experience!"